{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_images_fn = [fn for fn in os.listdir('pet_images') if fn.endswith('.jpg')]\n",
    "labels = []\n",
    "idx_to_labels = []\n",
    "label_to_idx = {}\n",
    "for fn in pet_images_fn:\n",
    "    label, _ = fn.rsplit('_', 1)\n",
    "    if not label in label_to_idx:\n",
    "        label_to_idx[label] = len(idx_to_labels)\n",
    "        idx_to_labels.append(label)\n",
    "    labels.append(label_to_idx[label])\n",
    "len(idx_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_pet(pet):\n",
    "    img = image.load_img('pet_images/' + pet, target_size=(299, 299))\n",
    "    return image.img_to_array(img)\n",
    "\n",
    "img_vector = np.asarray([fetch_pet(pet) for pet in pet_images_fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    }
   ],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "pool_2d = GlobalAveragePooling2D(name='pool_2d')(base_model.output)\n",
    "dense = Dense(1024, name='dense', activation='relu')(pool_2d)\n",
    "predictions = Dense(len(idx_to_labels), activation='softmax')(dense)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    }
   ],
   "source": [
    "# 0.9448\n",
    "y = np.zeros((len(labels), len(idx_to_labels)))\n",
    "for idx, label in enumerate(labels):\n",
    "    y[idx][label] = 1\n",
    "\n",
    "model.fit(\n",
    "    img_vector, y,\n",
    "    batch_size=128,\n",
    "    epochs=15,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unfreeze = False\n",
    "for layer in base_model.layers:\n",
    "    if unfreeze:\n",
    "        layer.trainable = True\n",
    "    if layer.name == 'mixed9':\n",
    "        unfreeze = True\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "35s - loss: 0.2204 - acc: 0.9530\n",
      "Epoch 2/15\n",
      "34s - loss: 0.0913 - acc: 0.9754\n",
      "Epoch 3/15\n",
      "35s - loss: 0.0484 - acc: 0.9859\n",
      "Epoch 4/15\n",
      "35s - loss: 0.0369 - acc: 0.9889\n",
      "Epoch 5/15\n",
      "35s - loss: 0.0331 - acc: 0.9911\n",
      "Epoch 6/15\n",
      "35s - loss: 0.0275 - acc: 0.9919\n",
      "Epoch 7/15\n",
      "35s - loss: 0.0238 - acc: 0.9938\n",
      "Epoch 8/15\n",
      "35s - loss: 0.0256 - acc: 0.9934\n",
      "Epoch 9/15\n",
      "35s - loss: 0.0213 - acc: 0.9957\n",
      "Epoch 10/15\n",
      "35s - loss: 0.0193 - acc: 0.9958\n",
      "Epoch 11/15\n",
      "35s - loss: 0.0185 - acc: 0.9961\n",
      "Epoch 12/15\n",
      "35s - loss: 0.0190 - acc: 0.9962\n",
      "Epoch 13/15\n",
      "35s - loss: 0.0194 - acc: 0.9961\n",
      "Epoch 14/15\n",
      "35s - loss: 0.0175 - acc: 0.9963\n",
      "Epoch 15/15\n",
      "35s - loss: 0.0172 - acc: 0.9963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fde235e5ac8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    img_vector, y,\n",
    "    batch_size=128,\n",
    "    epochs=15,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[(np.argsort(n)[-1], n[np.argsort(n)[-1]]) for n in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
