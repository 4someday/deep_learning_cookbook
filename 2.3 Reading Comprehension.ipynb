{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import nb_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "squad_training = json.load(\n",
    "    open(nb_utils.download('https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting our training data\n",
    "\n",
    "The squad training data is structured as a list of paragraphs, each with an associated set of questions.  Let's preprocess this a bit before we continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       " 'qas': [{'answers': [{'answer_start': 269, 'text': 'in the late 1990s'}],\n",
       "   'id': '56be85543aeaaa14008c9063',\n",
       "   'question': 'When did Beyonce start becoming popular?'},\n",
       "  {'answers': [{'answer_start': 207, 'text': 'singing and dancing'}],\n",
       "   'id': '56be85543aeaaa14008c9065',\n",
       "   'question': 'What areas did Beyonce compete in when she was growing up?'},\n",
       "  {'answers': [{'answer_start': 526, 'text': '2003'}],\n",
       "   'id': '56be85543aeaaa14008c9066',\n",
       "   'question': \"When did Beyonce leave Destiny's Child and become a solo singer?\"},\n",
       "  {'answers': [{'answer_start': 166, 'text': 'Houston, Texas'}],\n",
       "   'id': '56bf6b0f3aeaaa14008c9601',\n",
       "   'question': 'In what city and state did Beyonce  grow up? '},\n",
       "  {'answers': [{'answer_start': 276, 'text': 'late 1990s'}],\n",
       "   'id': '56bf6b0f3aeaaa14008c9602',\n",
       "   'question': 'In which decade did Beyonce become famous?'},\n",
       "  {'answers': [{'answer_start': 320, 'text': \"Destiny's Child\"}],\n",
       "   'id': '56bf6b0f3aeaaa14008c9603',\n",
       "   'question': 'In what R&B group was she the lead singer?'},\n",
       "  {'answers': [{'answer_start': 505, 'text': 'Dangerously in Love'}],\n",
       "   'id': '56bf6b0f3aeaaa14008c9604',\n",
       "   'question': 'What album made her a worldwide known artist?'},\n",
       "  {'answers': [{'answer_start': 360, 'text': 'Mathew Knowles'}],\n",
       "   'id': '56bf6b0f3aeaaa14008c9605',\n",
       "   'question': \"Who managed the Destiny's Child group?\"},\n",
       "  {'answers': [{'answer_start': 166, 'text': 'Houston'}],\n",
       "   'id': '56cef8faaab44d1400b88d67',\n",
       "   'question': 'In what city did Beyonce grow up?'},\n",
       "  {'answers': [{'answer_start': 505, 'text': 'Dangerously in Love'}],\n",
       "   'id': '56cef8faaab44d1400b88d68',\n",
       "   'question': \"What was the name of Beyonce's first solo album?\"},\n",
       "  {'answers': [{'answer_start': 64, 'text': 'September 4, 1981'}],\n",
       "   'id': '56cef8faaab44d1400b88d6a',\n",
       "   'question': 'On what date was Beyonce born?'},\n",
       "  {'answers': [{'answer_start': 0, 'text': 'Beyoncé Giselle Knowles-Carter'}],\n",
       "   'id': '56cef8faaab44d1400b88d6b',\n",
       "   'question': \"What is Beyonce's full name?\"},\n",
       "  {'answers': [{'answer_start': 276, 'text': 'late 1990s'}],\n",
       "   'id': '56d43c5f2ccc5a1400d830a9',\n",
       "   'question': 'When did Beyoncé rise to fame?'},\n",
       "  {'answers': [{'answer_start': 290, 'text': 'lead singer'}],\n",
       "   'id': '56d43c5f2ccc5a1400d830aa',\n",
       "   'question': \"What role did Beyoncé have in Destiny's Child?\"},\n",
       "  {'answers': [{'answer_start': 505, 'text': 'Dangerously in Love'}],\n",
       "   'id': '56d43c5f2ccc5a1400d830ab',\n",
       "   'question': 'What was the first album Beyoncé released as a solo artist?'},\n",
       "  {'answers': [{'answer_start': 526, 'text': '2003'}],\n",
       "   'id': '56d43c5f2ccc5a1400d830ac',\n",
       "   'question': 'When did Beyoncé release Dangerously in Love?'},\n",
       "  {'answers': [{'answer_start': 590, 'text': 'five'}],\n",
       "   'id': '56d43c5f2ccc5a1400d830ad',\n",
       "   'question': 'How many Grammy awards did Beyoncé win for her first solo album?'},\n",
       "  {'answers': [{'answer_start': 290, 'text': 'lead singer'}],\n",
       "   'id': '56d43ce42ccc5a1400d830b4',\n",
       "   'question': \"What was Beyoncé's role in Destiny's Child?\"},\n",
       "  {'answers': [{'answer_start': 505, 'text': 'Dangerously in Love'}],\n",
       "   'id': '56d43ce42ccc5a1400d830b5',\n",
       "   'question': \"What was the name of Beyoncé's first solo album?\"},\n",
       "  {'answers': [{'answer_start': 526, 'text': '2003'}],\n",
       "   'id': '56d43ce42ccc5a1400d830b6',\n",
       "   'question': 'When did Beyoncé release her first solo album?'}]}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_training['data'][1]['paragraphs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "VOCAB_SIZE = 250000\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_text = []\n",
    "\n",
    "for article in squad_training['data']:\n",
    "    for p in article['paragraphs']:\n",
    "        all_text.append(p['context'])\n",
    "        for qa in p['qas']:\n",
    "            all_text.append(qa['question'])\n",
    "            \n",
    "tokenizer.fit_on_texts(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_tokens = []\n",
    "answer_locations = []\n",
    "context_tokens = []\n",
    "\n",
    "for article in squad_training['data']:\n",
    "    for p in article['paragraphs']:\n",
    "        ct = tokenizer.texts_to_sequences([p['context']])[0]\n",
    "\n",
    "        for qa in p['qas']:\n",
    "            qt = tokenizer.texts_to_sequences([qa['question']])[0]\n",
    "            at = tokenizer.texts_to_sequences([qa['answers'][0]['text']])[0]\n",
    "            for j in range(len(ct) - len(at)):\n",
    "                if ct[j:j+len(at)] == at:\n",
    "                    question_tokens.append(qt)\n",
    "                    answer_locations.append((j, j + len(a)))\n",
    "                    context_tokens.append(ct)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.axes._subplots.AxesSubplot at 0x12fd8df60>,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x12fd8df60>,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x12fd8df60>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD8CAYAAACCRVh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFUNJREFUeJzt3X+w3XWd3/Hnq4lmURcUuU2zSWiyNbUTmO0qGcC64zjS\nStw6hj+ERteSdlOYDrQquzMuWTvrdKaZ0bYjWzuFGSouYVfAwLol48gKoo7TTgl7UVgImDXKr6RA\n4o+Vdlvpkn33j/NJPVzux4R7jjnnJs/HzJn7Oe/v93vO+2QCr3y+n+/33FQVkiTN569NugFJ0vQy\nJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqWjrpBhbqjDPOqDVr1ky6DUlaVO6/\n//7vVdXMse6/aENizZo1zM7OTroNSVpUkjzxcvb3dJMkqcuQkCR1GRKSpK6jhkSSzyQ5mOThebb9\nZpJKcsZQbVuSfUn2JrlwqH5Okofatk8lSasvS/K5Vt+dZM14PpokaVTHMpO4Edg4t5hkNfBO4Mmh\n2npgM3BWO+baJEva5uuAy4B17XHkNbcCP6yqNwDXAJ9YyAeRJI3fUUOiqr4O/GCeTdcAHwGGf2vR\nJuDWqnq+qh4D9gHnJlkBnFpV99bgtxzdBFw0dMyONr4duODILEOSNFkLWpNIsgk4UFUPztm0Enhq\n6Pn+VlvZxnPrLzqmql4AfgS8vvO+lyeZTTJ76NChhbQuSXoZXnZIJHkV8NvA74y/nZ+uqq6vqg1V\ntWFm5pjvBZEkLdBCZhJ/C1gLPJjkcWAV8I0kfwM4AKwe2ndVqx1o47l1ho9JshQ4Dfj+AvqSJI3Z\ny77juqoeAv76kectKDZU1feS7AJuTvJJ4BcYLFDfV1WHkzyX5HxgN3Ap8B/bS+wCtgD/HXgv8JW2\nbnHSuXn3k/PW33/emce5E0kaOJZLYG9h8D/wNybZn2Rrb9+q2gPsBB4B/hi4sqoOt81XAJ9msJj9\nHeDOVr8BeH2SfcBvAFcv8LNIksbsqDOJqnrfUbavmfN8O7B9nv1mgbPnqf8YuPhofUiSjj/vuJYk\ndRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVLX\ny/59Ejr+/D0TkibFmYQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlS11FDIslnkhxM8vBQ7d8l+VaS\nP03yR0leO7RtW5J9SfYmuXCofk6Sh9q2TyVJqy9L8rlW351kzXg/oiRpoY5lJnEjsHFO7W7g7Kr6\nJeDPgG0ASdYDm4Gz2jHXJlnSjrkOuAxY1x5HXnMr8MOqegNwDfCJhX4YSdJ4HTUkqurrwA/m1O6q\nqhfa03uBVW28Cbi1qp6vqseAfcC5SVYAp1bVvVVVwE3ARUPH7Gjj24ELjswyJEmTNY41iV8H7mzj\nlcBTQ9v2t9rKNp5bf9ExLXh+BLx+DH1JkkY0Ukgk+SjwAvDZ8bRz1Pe7PMlsktlDhw4dj7eUpJPa\ngkMiyT8B3g38WjuFBHAAWD2026pWO8BPTkkN1190TJKlwGnA9+d7z6q6vqo2VNWGmZmZhbYuSTpG\nCwqJJBuBjwDvqar/PbRpF7C5XbG0lsEC9X1V9TTwXJLz23rDpcAdQ8dsaeP3Al8ZCh1J0gQd9Vtg\nk9wCvB04I8l+4GMMrmZaBtzd1pjvrap/XlV7kuwEHmFwGurKqjrcXuoKBldKncJgDePIOsYNwO8n\n2cdggXzzeD6aJGlURw2JqnrfPOUbfsr+24Ht89RngbPnqf8YuPhofUiSjj/vuJYkdRkSkqQuQ0KS\n1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEld\nhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlS19Kj7ZDkM8C7gYNVdXarnQ58DlgDPA5cUlU/bNu2\nAVuBw8AHq+pLrX4OcCNwCvBF4ENVVUmWATcB5wDfB/5RVT0+tk94Art595Pz1t9/3pnHuRNJJ6pj\nmUncCGycU7sauKeq1gH3tOckWQ9sBs5qx1ybZEk75jrgMmBdexx5za3AD6vqDcA1wCcW+mEkSeN1\n1JCoqq8DP5hT3gTsaOMdwEVD9Vur6vmqegzYB5ybZAVwalXdW1XFYOZw0TyvdTtwQZIs9ANJksZn\noWsSy6vq6TZ+BljexiuBp4b2299qK9t4bv1Fx1TVC8CPgNcvsK8Fue2uq47n20nSojHywnWbGdQY\nejmqJJcnmU0ye+jQoePxlpJ0UltoSDzbTiHRfh5s9QPA6qH9VrXagTaeW3/RMUmWAqcxWMB+iaq6\nvqo2VNWGmZmZBbYuSTpWCw2JXcCWNt4C3DFU35xkWZK1DBao72unpp5Lcn5bb7h0zjFHXuu9wFfa\n7ESSNGHHcgnsLcDbgTOS7Ac+Bnwc2JlkK/AEcAlAVe1JshN4BHgBuLKqDreXuoKfXAJ7Z3sA3AD8\nfpJ9DBbIN4/lk0mSRnbUkKiq93U2XdDZfzuwfZ76LHD2PPUfAxcfrQ9J0vHnHdeSpC5DQpLUZUhI\nkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSp\ny5CQJHUZEpKkLkNCktRlSEiSugwJSVLX0kk3oPG7efeT89bff96Zx7kTSYvdSDOJJFcl2ZPk4SS3\nJPm5JKcnuTvJt9vP1w3tvy3JviR7k1w4VD8nyUNt26eSZJS+JEnjseCZRJKVwAeB9VX1f5LsBDYD\n64F7qurjSa4GrgZ+K8n6tv0s4BeALyf521V1GLgOuAzYDXwR2AjcOcLnmnq9f+1L0jQZdU1iKXBK\nkqXAq4D/AWwCdrTtO4CL2ngTcGtVPV9VjwH7gHOTrABOrap7q6qAm4aOkSRN0IJDoqoOAP8eeBJ4\nGvhRVd0FLK+qp9tuzwDL23gl8NTQS+xvtZVtPLcuSZqwBYdEW2vYBKxlcPro1Uk+MLxPmxnUSB2+\n+D0vTzKbZPbQoUPjellJUscop5v+PvBYVR2qqr8EPg/8PeDZdgqJ9vNg2/8AsHro+FWtdqCN59Zf\noqqur6oNVbVhZmZmhNYlScdilJB4Ejg/yava1UgXAI8Cu4AtbZ8twB1tvAvYnGRZkrXAOuC+dmrq\nuSTnt9e5dOgYSdIELfjqpqraneR24BvAC8A3geuB1wA7k2wFngAuafvvaVdAPdL2v7Jd2QRwBXAj\ncAqDq5pO6CubJGmxGOlmuqr6GPCxOeXnGcwq5tt/O7B9nvoscPYovUiSxs+v5ZAkdRkSkqQuQ0KS\n1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEs1td1016RYkaeoYEpKkLkNCktRlSEiSugwJ\nSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkrqWjnJwktcCnwbOBgr4dWAv8DlgDfA4\ncElV/bDtvw3YChwGPlhVX2r1c4AbgVOALwIfqqoapbdjcdtdV3HxO6/5Wb/N1Lh595Pz1t9/3pnH\nuRNJi8WoM4n/APxxVf0d4O8CjwJXA/dU1TrgnvacJOuBzcBZwEbg2iRL2utcB1wGrGuPjSP2JUka\ngwWHRJLTgLcBNwBU1f+tqj8HNgE72m47gIvaeBNwa1U9X1WPAfuAc5OsAE6tqnvb7OGmoWMkSRM0\nykxiLXAI+L0k30zy6SSvBpZX1dNtn2eA5W28Enhq6Pj9rbayjefWJUkTNkpILAXeDFxXVW8C/oJ2\naumINjMY29pCksuTzCaZPXTo0LheVpLUMUpI7Af2V9Xu9vx2BqHxbDuFRPt5sG0/AKweOn5Vqx1o\n47n1l6iq66tqQ1VtmJmZGaF1SdKxWHBIVNUzwFNJ3thKFwCPALuALa22BbijjXcBm5MsS7KWwQL1\nfe3U1HNJzk8S4NKhYyRJEzTSJbDAvwQ+m+SVwHeBf8ogeHYm2Qo8AVwCUFV7kuxkECQvAFdW1eH2\nOlfwk0tg72wPSdKEjRQSVfUAsGGeTRd09t8ObJ+nPsvgXgtJ0hTxjmtJUpchIUnqMiQkSV2GhCSp\ny5CQJHUZEpKkLkNCktRlSEiSugwJSVLXqF/LoROAv7FOUo8zCUlSlyEhSeoyJCRJXYaEJKnLkJAk\ndRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV0jh0SSJUm+meQL7fnpSe5O8u3283VD+25Lsi/J\n3iQXDtXPSfJQ2/apJBm1L0nS6MYxk/gQ8OjQ86uBe6pqHXBPe06S9cBm4CxgI3BtkiXtmOuAy4B1\n7bFxDH1JkkY0UkgkWQX8Q+DTQ+VNwI423gFcNFS/taqer6rHgH3AuUlWAKdW1b1VVcBNQ8dIkiZo\n1JnE7wIfAf5qqLa8qp5u42eA5W28EnhqaL/9rbayjefWJUkTtuCQSPJu4GBV3d/bp80MaqHvMc97\nXp5kNsnsoUOHxvWykqSOUWYSbwXek+Rx4FbgHUn+AHi2nUKi/TzY9j8ArB46flWrHWjjufWXqKrr\nq2pDVW2YmZkZoXVJ0rFYcEhU1baqWlVVaxgsSH+lqj4A7AK2tN22AHe08S5gc5JlSdYyWKC+r52a\nei7J+e2qpkuHjpEkTdDP4teXfhzYmWQr8ARwCUBV7UmyE3gEeAG4sqoOt2OuAG4ETgHubA9J0oSN\nJSSq6mvA19r4+8AFnf22A9vnqc8CZ4+jF0nS+HjHtSSp62dxukkniJt3Pzlv/f3nnXmcO5E0Kc4k\nJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXd5xPeS2u67i4ndeM9bX7N21\nLEmLgTMJSVKXISFJ6jIkJEldrkmMiWsPkk5EhoReNr9CXDp5eLpJktRlSEiSugwJSVKXISFJ6lpw\nSCRZneSrSR5JsifJh1r99CR3J/l2+/m6oWO2JdmXZG+SC4fq5yR5qG37VJKM9rEkSeMwykziBeA3\nq2o9cD5wZZL1wNXAPVW1DrinPadt2wycBWwErk2ypL3WdcBlwLr22DhCX5KkMVnwJbBV9TTwdBv/\nzySPAiuBTcDb2247gK8Bv9Xqt1bV88BjSfYB5yZ5HDi1qu4FSHITcBFw50J702R4aax04hnLmkSS\nNcCbgN3A8hYgAM8Ay9t4JfDU0GH7W21lG8+tS5ImbOSb6ZK8BvhD4MNV9dzwckJVVZIa9T2G3uty\n4HKAM8+czL9OvbNa0slkpJlEklcwCIjPVtXnW/nZJCva9hXAwVY/AKweOnxVqx1o47n1l6iq66tq\nQ1VtmJmZGaV1SdIxGOXqpgA3AI9W1SeHNu0CtrTxFuCOofrmJMuSrGWwQH1fOzX1XJLz22teOnSM\nJGmCRjnd9FbgHwMPJXmg1X4b+DiwM8lW4AngEoCq2pNkJ/AIgyujrqyqw+24K4AbgVMYLFi7aC1J\nU2CUq5v+K9C7n+GCzjHbge3z1GeBsxfaiyTpZ8M7riVJXYaEJKnLkJAkdflLh+a47a6ruPid10y6\njROKd2JLi9dJO5O47a6rJt2CJE29kzYkJElHZ0hIkrpck9DEuFYhTT9nEpKkLmcSHX7bqyQ5k5Ak\n/RTOJDR15pvFuU4hTYYzCUlSlyEhSeoyJObh3diSNGBISJK6DAlJUpdXN2lR8O5saTKcSUiSupxJ\naFFzhiH9bBkSOiG93K9VMVSk+U3N6aYkG5PsTbIvydWT7keSNCUziSRLgP8E/ANgP/AnSXZV1SOT\n6mn/d/8Nq37xX03q7XWcedpKmt9UhARwLrCvqr4LkORWYBMwsZAAg0KetpKmJSRWAk8NPd8PnDeh\nXl7CsNCxGtdXzBs2mhbTEhLHJMnlwOXt6f9KsneBL3UG8L3B8HePsut/nvNzYoZ6XjTseYF+7eXt\nPhU9L8Bi7PtE6PlvvpyDpyUkDgCrh56varUXqarrgetHfbMks1W1YdTXOZ7s+fiw5+NnMfZ9MvY8\nLVc3/QmwLsnaJK8ENgO7JtyTJJ30pmImUVUvJPkXwJeAJcBnqmrPhNuSpJPeVIQEQFV9EfjicXq7\nkU9ZTYA9Hx/2fPwsxr5Pup5TVeNqRJJ0gpmWNQlJ0hQ6qUJimr/6I8lnkhxM8vBQ7fQkdyf5dvv5\nuqFt29rn2Jvkwgn0uzrJV5M8kmRPkg8tgp5/Lsl9SR5sPf/rae95qI8lSb6Z5AuLqOfHkzyU5IEk\ns4uh7ySvTXJ7km8leTTJW6a55yRvbH++Rx7PJfnwWHuuqpPiwWBB/DvALwKvBB4E1k+6r6H+3ga8\nGXh4qPZvgavb+GrgE228vvW/DFjbPteS49zvCuDNbfzzwJ+1vqa55wCvaeNXALuB86e556HefwO4\nGfjCtP/dGOr5ceCMObWp7hvYAfyzNn4l8Npp73mo9yXAMwzugxhbzxP5MBP6A3wL8KWh59uAbZPu\na06Pa3hxSOwFVrTxCmDvfL0zuCrsLRPu/Q4G3721KHoGXgV8g8Gd/VPdM4P7hu4B3jEUElPdc3vv\n+UJiavsGTgMeo63VLoae5/T5TuC/jbvnk+l003xf/bFyQr0cq+VV9XQbPwMsb+Op+ixJ1gBvYvAv\n86nuuZ22eQA4CNxdVVPfM4OvBfgI8FdDtWnvGaCALye5v31bAkx332uBQ8DvtVN7n07yaqa752Gb\ngVvaeGw9n0whsajVIPan7lK0JK8B/hD4cFU9N7xtGnuuqsNV9csM/nV+bpKz52yfqp6TvBs4WFX3\n9/aZtp6H/Er7s34XcGWStw1vnMK+lzI45XtdVb0J+AsGp2r+vynsGYB2E/J7gNvmbhu155MpJI7p\nqz+mzLNJVgC0nwdbfSo+S5JXMAiIz1bV51t5qns+oqr+HPgqsJHp7vmtwHuSPA7cCrwjyR8w3T0D\nUFUH2s+DwB8x+Lbnae57P7C/zS4BbmcQGtPc8xHvAr5RVc+252Pr+WQKicX41R+7gC1tvIXBef8j\n9c1JliVZC6wD7juejSUJcAPwaFV9cmjTNPc8k+S1bXwKgzWUb01zz1W1rapWVdUaBn9nv1JVH5jm\nngGSvDrJzx8ZMzhf/jBT3HdVPQM8leSNrXQBg19XMLU9D3kfPznVBOPseVKLLBNa2PlVBlfhfAf4\n6KT7mdPbLcDTwF8y+BfNVuD1DBYsvw18GTh9aP+Pts+xF3jXBPr9FQZT2D8FHmiPX53ynn8J+Gbr\n+WHgd1p9anue0//b+cnC9VT3zOAqwgfbY8+R/94WQd+/DMy2vyP/BXjdIuj51cD3gdOGamPr2Tuu\nJUldJ9PpJknSy2RISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkrv8HqLpMIoAEIWsAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12ac54668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn\n",
    "[\n",
    "    seaborn.distplot([len(s) for s in context_tokens], kde=False),\n",
    "    seaborn.distplot([len(s) for s in question_tokens], kde=False),\n",
    "    seaborn.distplot([len(s) for s in answer_tokens], kde=False),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "\n",
    "def training_generator(bs=2):\n",
    "    while True:\n",
    "        batch_q = []\n",
    "        batch_c = []\n",
    "        start_idx = []\n",
    "        end_idx = []\n",
    "\n",
    "        idx = np.random.randint(0, len(context_tokens) - 1, size=bs)\n",
    "        for i in idx:\n",
    "            batch_q.append(question_tokens[i])\n",
    "            batch_c.append(context_tokens[i])\n",
    "            start_idx.append(answer_locations[i][0])\n",
    "            end_idx.append(answer_locations[i][1])\n",
    "        \n",
    "        batch_q = pad_sequences(batch_q)\n",
    "        batch_c = pad_sequences(batch_c)\n",
    "        onehot_start = np.zeros_like(batch_c)\n",
    "        onehot_end = np.zeros_like(batch_c)\n",
    "        onehot_start[np.arange(len(start_idx)), start_idx] = 1\n",
    "        onehot_end[np.arange(len(start_idx)), end_idx] = 1\n",
    "        \n",
    "        yield ({\n",
    "            'question': batch_q,\n",
    "            'context': batch_c,\n",
    "        }, {\n",
    "            'start_idx': onehot_start,\n",
    "            'end_idx': onehot_end,\n",
    "        })\n",
    "\n",
    "        \n",
    "tg = training_generator(5)\n",
    "for i in range(10):\n",
    "    x = next(tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None)\n",
      "(None, None, None)\n",
      "(None, None, None)\n",
      "(None, None, None)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "context (InputLayer)             (None, None)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "question (InputLayer)            (None, None)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_127 (Embedding)        (None, None, 50)      4594450     question[0][0]                   \n",
      "                                                                   context[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_316 (LSTM)                  (None, None, 50)      20200       embedding_127[1][0]              \n",
      "____________________________________________________________________________________________________\n",
      "lstm_315 (LSTM)                  (None, None, 50)      20200       embedding_127[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "lambda_220 (Lambda)              (None, None, 50)      0           lstm_315[0][0]                   \n",
      "                                                                   lstm_316[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_221 (Lambda)              (None, None, 50)      0           lstm_315[0][0]                   \n",
      "                                                                   lstm_316[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "multiply_82 (Multiply)           (None, None, 50)      0           lambda_220[0][0]                 \n",
      "                                                                   lstm_316[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "multiply_83 (Multiply)           (None, None, 50)      0           lambda_221[0][0]                 \n",
      "                                                                   lstm_316[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)    (None, None, 200)     0           lstm_316[0][0]                   \n",
      "                                                                   lambda_220[0][0]                 \n",
      "                                                                   multiply_82[0][0]                \n",
      "                                                                   multiply_83[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_63 (Bidirectional) (None, None, 100)     100400      concatenate_102[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_64 (Bidirectional) (None, None, 100)     60400       bidirectional_63[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)    (None, None, 300)     0           bidirectional_63[0][0]           \n",
      "                                                                   concatenate_102[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)    (None, None, 300)     0           bidirectional_64[0][0]           \n",
      "                                                                   concatenate_102[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_61 (TimeDistrib (None, None, 1)       301         concatenate_103[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_62 (TimeDistrib (None, None, 1)       301         concatenate_104[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "start_idx (Lambda)               (None, None)          0           time_distributed_61[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "end_idx (Lambda)                 (None, None)          0           time_distributed_62[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 4,796,252\n",
      "Trainable params: 4,796,252\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import layers, models\n",
    "from keras.layers import Bidirectional, LSTM\n",
    "import keras.backend as K\n",
    "\n",
    "HIDDEN_SIZE = 50\n",
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "def model(weights):\n",
    "    question = layers.Input(name='question', dtype='int32', shape=(None,))\n",
    "    context = layers.Input(name='context', dtype='int32', shape=(None,))\n",
    "    \n",
    "    embedding = layers.Embedding(\n",
    "        mask_zero=True,\n",
    "        input_dim=min(len(tokenizer.word_index), VOCAB_SIZE),\n",
    "        output_dim=EMBEDDING_SIZE,\n",
    "    )\n",
    "    \n",
    "    # Keras/Tensorflow doesn't have a builtin for outer products.  We\n",
    "    # can abuse how broadcasting works to accomplish it, by adding \n",
    "    # empty extra dimensions in the right places.\n",
    "    def outer_product(x, y):\n",
    "        batch_size = K.shape(x)[0]\n",
    "        w = K.shape(x)[1]\n",
    "        h = K.shape(y)[1]\n",
    "        outer_product = K.batch_dot(x, y, axes=(2,2))\n",
    "        print(K.int_shape(outer_product))\n",
    "#         outer_product = K.reshape(outer_product, (batch_size, w, h))\n",
    "        return outer_product\n",
    "    \n",
    "    def context2query(inputs):\n",
    "        question, context = inputs\n",
    "        op = outer_product(question, context)\n",
    "        e = K.exp(op - K.max(op, axis=2, keepdims=True))\n",
    "        s = K.sum(op, axis=2, keepdims=True)\n",
    "        softmax = e / s\n",
    "        \n",
    "        question = K.expand_dims(question, axis=2)\n",
    "        attention = K.expand_dims(softmax, axis=-1) * question\n",
    "        return K.sum(attention, axis=1)\n",
    "\n",
    "    def query2context(inputs):\n",
    "        question, context = inputs\n",
    "        op = outer_product(question, context)\n",
    "        attention = K.softmax(K.max(op, axis=1))\n",
    "        return context * K.expand_dims(attention, axis=-1)\n",
    "\n",
    "    encoded_question = Bidirectional(LSTM(units=HIDDEN_SIZE, return_sequences=True), merge_mode='concat')(embedding(question))\n",
    "    encoded_context = Bidirectional(LSTM(units=HIDDEN_SIZE, return_sequences=True), merge_mode='concat')(embedding(context))\n",
    "\n",
    "    # Take the softmax over the question, and sum the encoded contexts:\n",
    "    c2q = layers.Lambda(context2query)([encoded_question, encoded_context])\n",
    "    q2c = layers.Lambda(query2context)([encoded_question, encoded_context])\n",
    "    G = concatenate([encoded_context, \n",
    "                      c2q, \n",
    "                      layers.Multiply()([c2q, encoded_context]),\n",
    "                      layers.Multiply()([q2c, encoded_context]),\n",
    "                     ])\n",
    "\n",
    "    def flat_softmax(inputs):\n",
    "        return K.softmax(K.batch_flatten(inputs))\n",
    "    \n",
    "    M = Bidirectional(LSTM(units=HIDDEN_SIZE, return_sequences=True), merge_mode='concat')(G)\n",
    "    start_idx = layers.TimeDistributed(layers.Dense(units=1))(concatenate([M, G]))\n",
    "    start_idx = layers.Lambda(flat_softmax, name='start_idx')(start_idx)\n",
    "    \n",
    "    M2 = Bidirectional(LSTM(units=HIDDEN_SIZE, return_sequences=True), merge_mode='concat')(M)\n",
    "    end_idx = layers.TimeDistributed(layers.Dense(units=1))(concatenate([M2, G]))\n",
    "    end_idx = layers.Lambda(flat_softmax, name='end_idx')(end_idx)\n",
    "    model = models.Model(inputs=[question, context],\n",
    "                        outputs=[start_idx, end_idx])\n",
    "    \n",
    "    def idx_loss(y_true, y_pred):\n",
    "        \"Negative log loss for the true index.  y_true must be passed in as a one-hot vector.\"\n",
    "        return K.categorical_crossentropy(y_pred, y_true)\n",
    "    \n",
    "    model.compile(\n",
    "        metrics=['accuracy'],\n",
    "        optimizer='adam',\n",
    "        loss={'start_idx': 'categorical_crossentropy', 'end_idx': 'categorical_crossentropy'},\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "    \n",
    "m = model(weights=None)\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  40/1000 [>.............................] - ETA: 1386s - loss: 9.5923 - start_idx_loss: 4.7993 - end_idx_loss: 4.7929 - start_idx_acc: 0.0000e+00 - end_idx_acc: 0.0250"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-225-d6f0a2f2c86a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/power/anaconda3/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/power/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1838\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1839\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/power/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1563\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/power/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/power/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/power/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/power/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/power/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/power/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m.fit_generator(training_generator(bs=1), steps_per_epoch=1000, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
