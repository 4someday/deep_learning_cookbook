{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import nb_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "squad_training_json = json.load(\n",
    "    open(nb_utils.download('https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json'))\n",
    ")\n",
    "\n",
    "squad_test_json = json.load(\n",
    "    open(nb_utils.download('https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting our data\n",
    "\n",
    "The squad training data is structured as a list of paragraphs, each with an associated set of questions.  Let's preprocess this a bit before we continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       " 'qas': [{'answers': [{'answer_start': 269, 'text': 'in the late 1990s'}],\n",
       "   'id': '56be85543aeaaa14008c9063',\n",
       "   'question': 'When did Beyonce start becoming popular?'},\n",
       "  {'answers': [{'answer_start': 207, 'text': 'singing and dancing'}],\n",
       "   'id': '56be85543aeaaa14008c9065',\n",
       "   'question': 'What areas did Beyonce compete in when she was growing up?'},\n",
       "  {'answers': [{'answer_start': 526, 'text': '2003'}],\n",
       "   'id': '56be85543aeaaa14008c9066',\n",
       "   'question': \"When did Beyonce leave Destiny's Child and become a solo singer?\"},\n",
       "  {'answers': [{'answer_start': 166, 'text': 'Houston, Texas'}],\n",
       "   'id': '56bf6b0f3aeaaa14008c9601',\n",
       "   'question': 'In what city and state did Beyonce  grow up? '},\n",
       "  {'answers': [{'answer_start': 276, 'text': 'late 1990s'}],\n",
       "   'id': '56bf6b0f3aeaaa14008c9602',\n",
       "   'question': 'In which decade did Beyonce become famous?'},\n",
       "  {'answers': [{'answer_start': 320, 'text': \"Destiny's Child\"}],\n",
       "   'id': '56bf6b0f3aeaaa14008c9603',\n",
       "   'question': 'In what R&B group was she the lead singer?'},\n",
       "  {'answers': [{'answer_start': 505, 'text': 'Dangerously in Love'}],\n",
       "   'id': '56bf6b0f3aeaaa14008c9604',\n",
       "   'question': 'What album made her a worldwide known artist?'},\n",
       "  {'answers': [{'answer_start': 360, 'text': 'Mathew Knowles'}],\n",
       "   'id': '56bf6b0f3aeaaa14008c9605',\n",
       "   'question': \"Who managed the Destiny's Child group?\"},\n",
       "  {'answers': [{'answer_start': 166, 'text': 'Houston'}],\n",
       "   'id': '56cef8faaab44d1400b88d67',\n",
       "   'question': 'In what city did Beyonce grow up?'},\n",
       "  {'answers': [{'answer_start': 505, 'text': 'Dangerously in Love'}],\n",
       "   'id': '56cef8faaab44d1400b88d68',\n",
       "   'question': \"What was the name of Beyonce's first solo album?\"},\n",
       "  {'answers': [{'answer_start': 64, 'text': 'September 4, 1981'}],\n",
       "   'id': '56cef8faaab44d1400b88d6a',\n",
       "   'question': 'On what date was Beyonce born?'},\n",
       "  {'answers': [{'answer_start': 0, 'text': 'Beyoncé Giselle Knowles-Carter'}],\n",
       "   'id': '56cef8faaab44d1400b88d6b',\n",
       "   'question': \"What is Beyonce's full name?\"},\n",
       "  {'answers': [{'answer_start': 276, 'text': 'late 1990s'}],\n",
       "   'id': '56d43c5f2ccc5a1400d830a9',\n",
       "   'question': 'When did Beyoncé rise to fame?'},\n",
       "  {'answers': [{'answer_start': 290, 'text': 'lead singer'}],\n",
       "   'id': '56d43c5f2ccc5a1400d830aa',\n",
       "   'question': \"What role did Beyoncé have in Destiny's Child?\"},\n",
       "  {'answers': [{'answer_start': 505, 'text': 'Dangerously in Love'}],\n",
       "   'id': '56d43c5f2ccc5a1400d830ab',\n",
       "   'question': 'What was the first album Beyoncé released as a solo artist?'},\n",
       "  {'answers': [{'answer_start': 526, 'text': '2003'}],\n",
       "   'id': '56d43c5f2ccc5a1400d830ac',\n",
       "   'question': 'When did Beyoncé release Dangerously in Love?'},\n",
       "  {'answers': [{'answer_start': 590, 'text': 'five'}],\n",
       "   'id': '56d43c5f2ccc5a1400d830ad',\n",
       "   'question': 'How many Grammy awards did Beyoncé win for her first solo album?'},\n",
       "  {'answers': [{'answer_start': 290, 'text': 'lead singer'}],\n",
       "   'id': '56d43ce42ccc5a1400d830b4',\n",
       "   'question': \"What was Beyoncé's role in Destiny's Child?\"},\n",
       "  {'answers': [{'answer_start': 505, 'text': 'Dangerously in Love'}],\n",
       "   'id': '56d43ce42ccc5a1400d830b5',\n",
       "   'question': \"What was the name of Beyoncé's first solo album?\"},\n",
       "  {'answers': [{'answer_start': 526, 'text': '2003'}],\n",
       "   'id': '56d43ce42ccc5a1400d830b6',\n",
       "   'question': 'When did Beyoncé release her first solo album?'}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_training_json['data'][1]['paragraphs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "MAX_VOCAB_SIZE = 250000\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_text = []\n",
    "\n",
    "for article in squad_training_json['data'] + squad_test_json['data']:\n",
    "    for p in article['paragraphs']:\n",
    "        all_text.append(p['context'])\n",
    "        for qa in p['qas']:\n",
    "            all_text.append(qa['question'])\n",
    "            \n",
    "tokenizer.fit_on_texts(all_text)\n",
    "vocab_size = min(len(tokenizer.word_index) + 1, MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_data(dataset):\n",
    "    question_tokens = []\n",
    "    answer_locations = []\n",
    "    context_tokens = []\n",
    "\n",
    "    for article in dataset['data']:\n",
    "        for p in article['paragraphs']:\n",
    "            ct = tokenizer.texts_to_sequences([p['context']])[0]\n",
    "\n",
    "            for qa in p['qas']:\n",
    "                qt = tokenizer.texts_to_sequences([qa['question']])[0]\n",
    "                at = tokenizer.texts_to_sequences([qa['answers'][0]['text']])[0]\n",
    "                for j in range(len(ct) - len(at)):\n",
    "                    if ct[j:j+len(at)] == at:\n",
    "                        question_tokens.append(qt)\n",
    "                        answer_locations.append((j, j + len(at)))\n",
    "                        context_tokens.append(ct)\n",
    "                        break\n",
    "    \n",
    "    return {\n",
    "        'q': question_tokens,\n",
    "        'a': answer_locations,\n",
    "        'ctx': context_tokens\n",
    "    }\n",
    "\n",
    "squad_train = prep_data(squad_training_json)\n",
    "squad_test = prep_data(squad_test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.axes._subplots.AxesSubplot at 0x7f24c4dff5f8>,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x7f24c4dff5f8>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAFXCAYAAABOYlxEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAxEwAMAYKD/BxXodcERn0WqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f24c8ff1c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn\n",
    "[\n",
    "    seaborn.distplot([len(s) for s in squad_train['ctx']], kde=False),\n",
    "    seaborn.distplot([len(s) for s in squad_train['q']], kde=False),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained word vectors\n",
    "\n",
    "We don't have a lot of training data for the Squad dataset, so instead of training our word vectors from scratch, let's start with pre-trained vectors.  This will allow our network to focus on learning parameters that optimize finding the right words in our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "EMBEDDING_SIZE = 50\n",
    "word_vectors = np.zeros((vocab_size, EMBEDDING_SIZE))\n",
    "\n",
    "with open('/home/power/Downloads/glove.6B.%dd.txt' % EMBEDDING_SIZE, 'r') as f:\n",
    "    for line in f:\n",
    "        word, ary = line.split(' ', 1)\n",
    "        if word in tokenizer.word_index:\n",
    "            word_vectors[tokenizer.word_index[word]] = np.fromstring(ary, sep=' ', dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foxx 0.708784659092\n",
      "aretha 0.711284679727\n",
      "stevie 0.716988531102\n",
      "kanye 0.73881587196\n",
      "knowles 0.742291995652\n",
      "timberlake 0.768287273499\n",
      "beyoncé 0.779903867891\n",
      "blige 0.782109394434\n",
      "mariah 0.802994181335\n",
      "beyonce 0.999999999982\n"
     ]
    }
   ],
   "source": [
    "def sim(A, b):\n",
    "    am = 1e-9 + np.sum(A * A, axis=1)\n",
    "    bm = np.dot(b, b)\n",
    "    sim = np.dot(A, b) / (np.sqrt(am) * np.sqrt(bm))\n",
    "    sim_idx = np.argsort(sim)\n",
    "    return zip(sim_idx[-10:], sim[sim_idx[-10:]])\n",
    "\n",
    "idx_to_word = {v:k for k,v in tokenizer.word_index.items()}\n",
    "idx_to_word[0] = 'n/a'\n",
    "for idx, dist in sim(word_vectors, word_vectors[tokenizer.word_index['beyonce']]):\n",
    "    print(idx_to_word[idx], dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': ['n/a', 'n/a'],\n",
       " 'ctx': ['n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'when',\n",
       "  'russia',\n",
       "  'invaded',\n",
       "  'the',\n",
       "  'turkish',\n",
       "  'balkans',\n",
       "  'in',\n",
       "  '1853',\n",
       "  'fears',\n",
       "  'of',\n",
       "  'russian',\n",
       "  'dominance',\n",
       "  'in',\n",
       "  'the',\n",
       "  'mediterranean',\n",
       "  'and',\n",
       "  'middle',\n",
       "  'east',\n",
       "  'led',\n",
       "  'britain',\n",
       "  'and',\n",
       "  'france',\n",
       "  'to',\n",
       "  'invade',\n",
       "  'the',\n",
       "  'crimean',\n",
       "  'peninsula',\n",
       "  'to',\n",
       "  'destroy',\n",
       "  'russian',\n",
       "  'naval',\n",
       "  'capabilities',\n",
       "  'the',\n",
       "  'ensuing',\n",
       "  'crimean',\n",
       "  'war',\n",
       "  '1854–56',\n",
       "  'which',\n",
       "  'involved',\n",
       "  'new',\n",
       "  'techniques',\n",
       "  'of',\n",
       "  'modern',\n",
       "  'warfare',\n",
       "  'and',\n",
       "  'was',\n",
       "  'the',\n",
       "  'only',\n",
       "  'global',\n",
       "  'war',\n",
       "  'fought',\n",
       "  'between',\n",
       "  'britain',\n",
       "  'and',\n",
       "  'another',\n",
       "  'imperial',\n",
       "  'power',\n",
       "  'during',\n",
       "  'the',\n",
       "  'pax',\n",
       "  'britannica',\n",
       "  'was',\n",
       "  'a',\n",
       "  'resounding',\n",
       "  'defeat',\n",
       "  'for',\n",
       "  'russia',\n",
       "  'the',\n",
       "  'situation',\n",
       "  'remained',\n",
       "  'unresolved',\n",
       "  'in',\n",
       "  'central',\n",
       "  'asia',\n",
       "  'for',\n",
       "  'two',\n",
       "  'more',\n",
       "  'decades',\n",
       "  'with',\n",
       "  'britain',\n",
       "  'annexing',\n",
       "  'baluchistan',\n",
       "  'in',\n",
       "  '1876',\n",
       "  'and',\n",
       "  'russia',\n",
       "  'annexing',\n",
       "  'kirghizia',\n",
       "  'kazakhstan',\n",
       "  'and',\n",
       "  'turkmenistan',\n",
       "  'for',\n",
       "  'a',\n",
       "  'while',\n",
       "  'it',\n",
       "  'appeared',\n",
       "  'that',\n",
       "  'another',\n",
       "  'war',\n",
       "  'would',\n",
       "  'be',\n",
       "  'inevitable',\n",
       "  'but',\n",
       "  'the',\n",
       "  'two',\n",
       "  'countries',\n",
       "  'reached',\n",
       "  'an',\n",
       "  'agreement',\n",
       "  'on',\n",
       "  'their',\n",
       "  'respective',\n",
       "  'spheres',\n",
       "  'of',\n",
       "  'influence',\n",
       "  'in',\n",
       "  'the',\n",
       "  'region',\n",
       "  'in',\n",
       "  '1878',\n",
       "  'and',\n",
       "  'on',\n",
       "  'all',\n",
       "  'outstanding',\n",
       "  'matters',\n",
       "  'in',\n",
       "  '1907',\n",
       "  'with',\n",
       "  'the',\n",
       "  'signing',\n",
       "  'of',\n",
       "  'the',\n",
       "  'anglo',\n",
       "  'russian',\n",
       "  'entente',\n",
       "  'the',\n",
       "  'destruction',\n",
       "  'of',\n",
       "  'the',\n",
       "  'russian',\n",
       "  'navy',\n",
       "  'by',\n",
       "  'the',\n",
       "  'japanese',\n",
       "  'at',\n",
       "  'the',\n",
       "  'battle',\n",
       "  'of',\n",
       "  'port',\n",
       "  'arthur',\n",
       "  'during',\n",
       "  'the',\n",
       "  'russo',\n",
       "  'japanese',\n",
       "  'war',\n",
       "  'of',\n",
       "  '1904–05',\n",
       "  'also',\n",
       "  'limited',\n",
       "  'its',\n",
       "  'threat',\n",
       "  'to',\n",
       "  'the',\n",
       "  'british'],\n",
       " 'q': ['n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'n/a',\n",
       "  'what',\n",
       "  'was',\n",
       "  'took',\n",
       "  'place',\n",
       "  'in',\n",
       "  '1854',\n",
       "  '1856']}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "\n",
    "def training_generator(dataset, bs):\n",
    "    while True:\n",
    "        batch_q = []\n",
    "        batch_c = []\n",
    "        start_idx = []\n",
    "        end_idx = []\n",
    "        \n",
    "        q, a, ctx = dataset['q'], dataset['a'], dataset['ctx']\n",
    "\n",
    "        idx = np.random.randint(0, len(ctx) - 1, size=bs)\n",
    "        for i in idx:\n",
    "            batch_q.append(q[i])\n",
    "            batch_c.append(ctx[i])\n",
    "            start_idx.append(a[i][0])\n",
    "            end_idx.append(a[i][1])\n",
    "        \n",
    "        batch_q = pad_sequences(batch_q)\n",
    "        batch_c = pad_sequences(batch_c)\n",
    "        onehot_start = np.zeros_like(batch_c)\n",
    "        onehot_end = np.zeros_like(batch_c)\n",
    "        onehot_start[np.arange(len(start_idx)), start_idx] = 1\n",
    "        onehot_end[np.arange(len(start_idx)), end_idx] = 1\n",
    "        \n",
    "        yield ({\n",
    "            'question': batch_q,\n",
    "            'context': batch_c,\n",
    "        }, {\n",
    "            'start_idx': onehot_start,\n",
    "            'end_idx': onehot_end,\n",
    "        })\n",
    "\n",
    "        \n",
    "tg = training_generator(squad_train, 32)\n",
    "for i in range(10):\n",
    "    x, y = next(tg)\n",
    "\n",
    "s_idx = np.nonzero(y['start_idx'])[1][0]\n",
    "e_idx = np.nonzero(y['end_idx'])[1][0]\n",
    "\n",
    "{ \n",
    "    'ctx': [idx_to_word[w] for w in x['context'][0]],\n",
    "    'q': [idx_to_word[w] for w in x['question'][0]],\n",
    "    'a': [idx_to_word[w] for w in x['context'][0][s_idx:e_idx]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "context (InputLayer)             (None, None)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "question (InputLayer)            (None, None)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)          (None, None, 50)      4884450     question[0][0]                   \n",
      "                                                                   context[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "att (Lambda)                     (None, None, None)    0           embedding_8[0][0]                \n",
      "                                                                   embedding_8[1][0]                \n",
      "____________________________________________________________________________________________________\n",
      "c2q (Lambda)                     (None, None, 50)      0           embedding_8[0][0]                \n",
      "                                                                   embedding_8[1][0]                \n",
      "                                                                   att[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "q2c (Lambda)                     (None, None, 50)      0           embedding_8[0][0]                \n",
      "                                                                   embedding_8[1][0]                \n",
      "                                                                   att[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "sel_c2q (Multiply)               (None, None, 50)      0           c2q[0][0]                        \n",
      "                                                                   embedding_8[1][0]                \n",
      "____________________________________________________________________________________________________\n",
      "sel_q2c (Multiply)               (None, None, 50)      0           q2c[0][0]                        \n",
      "                                                                   embedding_8[1][0]                \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, None, 200)     0           embedding_8[1][0]                \n",
      "                                                                   c2q[0][0]                        \n",
      "                                                                   sel_c2q[0][0]                    \n",
      "                                                                   sel_q2c[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional)  (None, None, 100)     100400      concatenate_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "idx_input (Concatenate)          (None, None, 300)     0           bidirectional_6[0][0]            \n",
      "                                                                   concatenate_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "start_idx_lstm (Bidirectional)   (None, None, 100)     140400      idx_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "end_idx_lstm (Bidirectional)     (None, None, 100)     140400      idx_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistrib (None, None, 1)       101         start_idx_lstm[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistrib (None, None, 1)       101         end_idx_lstm[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "start_idx (Lambda)               (None, None)          0           time_distributed_13[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "end_idx (Lambda)                 (None, None)          0           time_distributed_14[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 5,265,852\n",
      "Trainable params: 381,402\n",
      "Non-trainable params: 4,884,450\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import layers, models\n",
    "from keras.layers import Bidirectional, LSTM\n",
    "import keras.backend as K\n",
    "\n",
    "HIDDEN_SIZE = 50\n",
    "# l2 = keras.regularizers.l2(l=0.001)\n",
    "\n",
    "\n",
    "# Keras/Tensorflow doesn't have a builtin for outer products.  We\n",
    "# can abuse how broadcasting works to accomplish it, by adding \n",
    "# empty extra dimensions in the right places.\n",
    "def matrix_attention(inputs):\n",
    "    x, y = inputs\n",
    "    outer_product = K.batch_dot(x, y, axes=(2,2))\n",
    "    return outer_product\n",
    "\n",
    "def context2query(inputs):\n",
    "    question, context, op = inputs\n",
    "    e = K.exp(op - K.max(op, axis=2, keepdims=True))\n",
    "    s = 1e-4 + K.sum(op, axis=2, keepdims=True)\n",
    "    softmax = e / s\n",
    "\n",
    "    question = K.expand_dims(question, axis=2)\n",
    "    attention = K.expand_dims(softmax, axis=-1) * question\n",
    "    return K.sum(attention, axis=1)\n",
    "\n",
    "def query2context(inputs):\n",
    "    question, context, op = inputs\n",
    "    attention = K.softmax(K.max(op, axis=1))\n",
    "    return context * K.expand_dims(attention, axis=-1)\n",
    "\n",
    "def bilstm(*args, **kw):\n",
    "#         kw['kernel_regularizer'] = l2\n",
    "#         kw['dropout'] = 0.2\n",
    "    if 'name' in kw:\n",
    "        name = kw['name']\n",
    "        del kw['name']\n",
    "    else:\n",
    "        name = None\n",
    "    return Bidirectional(LSTM(*args, **kw), merge_mode='concat', name=name)\n",
    "\n",
    "def flat_softmax(inputs):\n",
    "    return K.softmax(K.batch_flatten(inputs))\n",
    "\n",
    "\n",
    "def softsel(inputs):\n",
    "    sel, mat = inputs\n",
    "    orig_shape = K.shape(mat)\n",
    "    mat = K.sum(mat * sel, axis=-1)\n",
    "    mat = K.expand_dims(mat, 1)\n",
    "    mat = K.expand_dims(mat, 1)\n",
    "    return K.reshape(mat, orig_shape)\n",
    "\n",
    "def model():\n",
    "    question = layers.Input(name='question', dtype='int32', shape=(None,))\n",
    "    context = layers.Input(name='context', dtype='int32', shape=(None,))\n",
    "    \n",
    "    embedding = layers.Embedding(\n",
    "        mask_zero=True,\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=EMBEDDING_SIZE,\n",
    "        weights=[word_vectors],\n",
    "        trainable=False,\n",
    "    )\n",
    "\n",
    "    encoded_question = embedding(question)\n",
    "    encoded_context = embedding(context)\n",
    "    \n",
    "    encoded_question = bilstm(encoded_question)\n",
    "    encoded_context = bilstm(encoded_context)\n",
    "\n",
    "    matrix_att = layers.Lambda(matrix_attention, name='att')([encoded_question, encoded_context])\n",
    "    c2q = layers.Lambda(context2query, name='c2q')([encoded_question, encoded_context, matrix_att])\n",
    "    q2c = layers.Lambda(query2context, name='q2c')([encoded_question, encoded_context, matrix_att])\n",
    "    G = concatenate([encoded_context, \n",
    "                      c2q, \n",
    "                      layers.Multiply(name='sel_c2q')([c2q, encoded_context]),\n",
    "                      layers.Multiply(name='sel_q2c')([q2c, encoded_context]),\n",
    "                     ])\n",
    "\n",
    "    M = bilstm(units=HIDDEN_SIZE, return_sequences=True)(G)\n",
    "    \n",
    "    idx_input = concatenate([M, G], name='idx_input')\n",
    "\n",
    "    start_idx = bilstm(units=HIDDEN_SIZE, return_sequences=True, name='start_idx_lstm')(idx_input)\n",
    "    start_idx = layers.TimeDistributed(layers.Dense(units=1))(start_idx)\n",
    "    start_idx = layers.Lambda(flat_softmax, name='start_idx')(start_idx)\n",
    "    \n",
    "    end_idx = bilstm(units=HIDDEN_SIZE, return_sequences=True, name='end_idx_lstm')(idx_input)\n",
    "    end_idx = layers.TimeDistributed(layers.Dense(units=1))(end_idx)\n",
    "    end_idx = layers.Lambda(flat_softmax, name='end_idx')(end_idx)\n",
    "    \n",
    "    model = models.Model(inputs=[question, context],\n",
    "                        outputs=[start_idx, end_idx])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "import tensorflow as tf\n",
    "m = model()\n",
    "m.compile(\n",
    "    metrics=['accuracy'],\n",
    "    optimizer='adam',\n",
    "    loss={'start_idx': 'categorical_crossentropy', 'end_idx': 'categorical_crossentropy'},\n",
    ")\n",
    "\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.01483208,  0.01383604,  0.01238179,  0.01164735,  0.01106084,\n",
       "          0.0100648 ,  0.01262134,  0.0130599 ,  0.01286688,  0.0112294 ,\n",
       "          0.01096907,  0.01059796,  0.01095027,  0.00982713,  0.00954198,\n",
       "          0.01114662,  0.01279745,  0.01445914,  0.01583774,  0.0157361 ,\n",
       "          0.01398905,  0.01265113,  0.0119996 ,  0.01440606,  0.01520634,\n",
       "          0.01457738,  0.01396388,  0.01262292,  0.00996734,  0.01014959,\n",
       "          0.00827183,  0.00917331,  0.00944578,  0.0095413 ,  0.00916815,\n",
       "          0.01009691,  0.01315981,  0.01458935,  0.01604154,  0.015453  ,\n",
       "          0.0150847 ,  0.01566288,  0.01474436,  0.01580637,  0.01444684,\n",
       "          0.01479789,  0.01336432,  0.01225285,  0.01193167,  0.01166679,\n",
       "          0.01250943,  0.01349258,  0.01302106,  0.01290794,  0.01395621,\n",
       "          0.01294354,  0.01181662,  0.01217321,  0.01141638,  0.01217545,\n",
       "          0.01200444,  0.01227443,  0.01378706,  0.01424229,  0.01408861,\n",
       "          0.01285938,  0.01354672,  0.01351656,  0.01370217,  0.01286795,\n",
       "          0.01309597,  0.01280959,  0.01174328,  0.01348103,  0.0132488 ,\n",
       "          0.01210686,  0.01088802,  0.01046681,  0.01316081]], dtype=float32),\n",
       " array([[ 0.01287087,  0.0132165 ,  0.01297667,  0.01265473,  0.01306406,\n",
       "          0.01373884,  0.01258544,  0.01404591,  0.01303258,  0.01112068,\n",
       "          0.01120642,  0.01213204,  0.01350886,  0.01487177,  0.01358387,\n",
       "          0.01298712,  0.01399594,  0.01427075,  0.01394555,  0.01258601,\n",
       "          0.01355059,  0.01256053,  0.0129451 ,  0.01273496,  0.01223043,\n",
       "          0.01309023,  0.01213156,  0.01166046,  0.01008132,  0.01098784,\n",
       "          0.01257568,  0.01185685,  0.01335534,  0.01544087,  0.01677208,\n",
       "          0.01578481,  0.01377615,  0.01365706,  0.01321615,  0.01404097,\n",
       "          0.01280402,  0.01303031,  0.01293512,  0.01293532,  0.01202211,\n",
       "          0.01172753,  0.01133581,  0.01194502,  0.01185128,  0.01235508,\n",
       "          0.01167552,  0.01254775,  0.01293632,  0.01231536,  0.01254709,\n",
       "          0.01308914,  0.01274089,  0.01184715,  0.01103063,  0.01053841,\n",
       "          0.01207051,  0.01338132,  0.01324795,  0.01300366,  0.01326419,\n",
       "          0.01299692,  0.01324483,  0.01181336,  0.01266674,  0.01175131,\n",
       "          0.01094419,  0.01157954,  0.01272784,  0.01167865,  0.01113266,\n",
       "          0.01119787,  0.01096027,  0.01144425,  0.01184039]], dtype=float32)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(training_generator(squad_train, bs=1))\n",
    "m.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "    7/10000 [..............................] - ETA: 37410s - loss: 10.1994 - start_idx_loss: 5.1117 - end_idx_loss: 5.0877 - start_idx_acc: 0.0000e+00 - end_idx_acc: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-533e5cb426c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquad_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1900\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1901\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1640\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m.fit_generator(training_generator(squad_train, bs=8), steps_per_epoch=10000, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
